import snowflake.connector
import pandas as pd
import plotly.express as px

def run_data_quality_checks(table_list, column_checks, conn):
    data = []
    for table_name in table_list:
        for col_name, checks in column_checks[table_name].items():
            for check_type, check_script in checks.items():
                query = f"SELECT COUNT(*) FROM {table_name} WHERE {col_name} IS NOT NULL AND {check_script};"
                cursor = conn.cursor()
                cursor.execute(query)
                result = cursor.fetchone()[0]
                if result > 0:
                    print(f"Data quality issue detected in table '{table_name}', column '{col_name}', check '{check_type}': {result} rows failed the check.")
                    data.append([table_name, col_name, check_type, result])
                else:
                    print(f"No data quality issues detected in table '{table_name}', column '{col_name}', check '{check_type}'.")
    return pd.DataFrame(data, columns=['Table Name', 'Column Name', 'Check Type', 'Issue Count'])

# Define the Snowflake credentials and connect to Snowflake
conn = snowflake.connector.connect(
    user='<your_user>',
    password='<your_password>',
    account='<your_account>',
    database='<your_database>',
    schema='<your_schema>',
    warehouse='<your_warehouse>'
)

# Define the tables and columns to check, along with the data quality checks to perform for each column
table_list = ['table1', 'table2', 'table3']
column_checks = {
    'table1': {
        'col1': {
            'Null Check': 'IS NULL',
            'Pattern Check': "NOT REGEXP_LIKE(col1, '[A-Za-z0-9_]+')",
            'Outlier Check': "ABS(col1 - AVG(col1)) > 3 * STDDEV(col1)"
        },
        'col2': {
            'Null Check': 'IS NULL',
            'Type Check': 'TRY_TO_TIMESTAMP(col2) IS NULL'
        }
    },
    'table2': {
        'col3': {
            'Null Check': 'IS NULL',
            'Range Check': 'col3 BETWEEN 0 AND 100',
            'Duplicate Check': f"{'col3'} IN (SELECT {'col3'} FROM {'table2'} GROUP BY {'col3'} HAVING COUNT(*) > 1)"
        },
        'col4': {
            'Null Check': 'IS NULL',
            'Pattern Check': "NOT REGEXP_LIKE(col4, '[A-Za-z0-9_]+')",
            'Outlier Check': "ABS(col4 - AVG(col4)) > 3 * STDDEV(col4)"
        }
    },
    'table3': {
        'col5': {
            'Null Check': 'IS NULL',
            'Type Check': 'TRY_TO_TIMESTAMP(col5) IS NULL'
        },
        'col6': {
            'Null Check': 'IS NULL',
            'Duplicate Check': f"{'col6'} IN (SELECT {'col6'} FROM {'table3'} GROUP BY {'col6'} HAVING COUNT(*) > 1)",
            'Outlier Check': "ABS(col6 - AVG(col6)) > 3 * STDDEV(col6)"
        }
    }
}

# Run the data quality checks and get the results as a Pandas DataFrame
df = run_data_quality_checks(table_list, column_checks, conn)

# Close the Snowflake connection
conn.close()

if not df.empty:
# Create a pie chart to display the data quality issues by table name
fig = px.pie(df, values='Issue Count', names='Table Name', title='Data Quality Issues by Table Name')

# Show the chart
fig.show()
